{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import helpers\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import multiprocessing as mp\n",
    "import os \n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# Load the data from files\n",
    "with open(f'{DATA_DIR}/corpus.jsonl', 'r') as f:\n",
    "    corpus_data = {int(item['_id']): item['text'] for item in (json.loads(line) for line in f)}\n",
    "\n",
    "with open(f'{DATA_DIR}/queries.jsonl', 'r') as f:\n",
    "    queries_data = {int(item['_id']): item['text'] for item in (json.loads(line) for line in f)}\n",
    "\n",
    "train_data = pd.read_csv(f'{DATA_DIR}/task1_train.tsv', delimiter='\\t')\n",
    "test_data = pd.read_csv(f'{DATA_DIR}/task1_test.tsv', delimiter='\\t')\n",
    "\n",
    "# Rename corpus-id to document_id and query-id to query_id in both train and test data\n",
    "train_data = train_data.rename(columns={'corpus-id': 'document_id', 'query-id': 'query_id'})\n",
    "test_data = test_data.rename(columns={'corpus-id': 'document_id', 'query-id': 'query_id'})\n",
    "# Make sure that the document_id and query_id are int64\n",
    "train_data['document_id'] = train_data['document_id'].astype('int64')\n",
    "train_data['query_id'] = train_data['query_id'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df from the corpus data\n",
    "corpus_df = pd.DataFrame.from_dict(corpus_data, orient='index', columns=['text'])\n",
    "# Create a df from the queries data\n",
    "queries_df = pd.DataFrame.from_dict(queries_data, orient='index', columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1471406"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import partial\n",
    "# from functools import partial\n",
    "\n",
    "# documents = corpus_df['text'].tolist()\n",
    "# documents = [x.strip() for x in documents]\n",
    "# documents = [simple_preprocess(doc) for i, doc in tqdm(enumerate(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as line_sentence\n",
    "from gensim.utils import save_as_line_sentence\n",
    "#save_as_line_sentence(documents, f'{DATA_DIR}/tagged_documents_linesentence.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "\n",
    "    '''Callback to save model after each epoch.'''\n",
    "\n",
    "\n",
    "    def __init__(self, path_prefix):\n",
    "\n",
    "        self.path_prefix = path_prefix\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "\n",
    "        output_path = get_tmpfile('{}_epoch{}.model'.format(self.path_prefix, self.epoch))\n",
    "\n",
    "        model.save(output_path)\n",
    "\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "\n",
    "    '''Callback to log information about training'''\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "\n",
    "        print(\"Epoch #{} start\".format(self.epoch))\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        #print loss\n",
    "        print(\"Loss: {}\".format(model.get_latest_training_loss()))\n",
    "\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = EpochLogger()\n",
    "model = Doc2Vec(vector_size=400, epochs=20, workers=mp.cpu_count(), dm=0, sample=0.00001, window=20, min_count=1)\n",
    "model.build_vocab(corpus_file=f'{DATA_DIR}/tagged_documents_linesentence.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Loss: 0.0\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Loss: 0.0\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Loss: 0.0\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Loss: 0.0\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Loss: 0.0\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Loss: 0.0\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Loss: 0.0\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Loss: 0.0\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Loss: 0.0\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n",
      "Loss: 0.0\n",
      "Epoch #10 start\n",
      "Epoch #10 end\n",
      "Loss: 0.0\n",
      "Epoch #11 start\n",
      "Epoch #11 end\n",
      "Loss: 0.0\n",
      "Epoch #12 start\n",
      "Epoch #12 end\n",
      "Loss: 0.0\n",
      "Epoch #13 start\n",
      "Epoch #13 end\n",
      "Loss: 0.0\n",
      "Epoch #14 start\n",
      "Epoch #14 end\n",
      "Loss: 0.0\n",
      "Epoch #15 start\n",
      "Epoch #15 end\n",
      "Loss: 0.0\n",
      "Epoch #16 start\n",
      "Epoch #16 end\n",
      "Loss: 0.0\n",
      "Epoch #17 start\n",
      "Epoch #17 end\n",
      "Loss: 0.0\n",
      "Epoch #18 start\n",
      "Epoch #18 end\n",
      "Loss: 0.0\n",
      "Epoch #19 start\n",
      "Epoch #19 end\n",
      "Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "model.train(corpus_file=f'{DATA_DIR}/tagged_documents_linesentence.txt', total_examples=len(corpus_df), total_words=model.corpus_total_words, epochs=model.epochs, report_delay=10, callbacks=[logger], compute_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jt/f2yqrnv562q34hfjkkskqwzw0000gn/T/ipykernel_8116/2522894730.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  len(model.docvecs[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.docvecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import get tmpfile\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "fname = get_tmpfile(\"doc2vec_model2\")\n",
    "model.save(f'{DATA_DIR}/doc2vec_model2.model')\n",
    "# load model\n",
    "#model = Doc2Vec.load(f'{DATA_DIR}/larger_400_doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what',\n",
       " 'was',\n",
       " 'the',\n",
       " 'immediate',\n",
       " 'impact',\n",
       " 'of',\n",
       " 'the',\n",
       " 'success',\n",
       " 'of',\n",
       " 'the',\n",
       " 'manhattan',\n",
       " 'project']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first query\n",
    "query = queries_df.iloc[0]['text']\n",
    "query = simple_preprocess(query)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = model.infer_vector(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jt/f2yqrnv562q34hfjkkskqwzw0000gn/T/ipykernel_8116/1092452515.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  sims = model.docvecs.most_similar([query_vector]) #gives you top 10 document tags and their cosine similarity\n"
     ]
    }
   ],
   "source": [
    "sims = model.docvecs.most_similar([query_vector]) #gives you top 10 document tags and their cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(414557, 0.6452532410621643),\n",
       " (989485, 0.6444576382637024),\n",
       " (1214391, 0.6429510712623596),\n",
       " (45110, 0.6416457891464233),\n",
       " (1241283, 0.6410707831382751),\n",
       " (412685, 0.6367886066436768),\n",
       " (1461974, 0.6362625360488892),\n",
       " (696563, 0.6349706649780273),\n",
       " (906517, 0.6323652267456055),\n",
       " (309150, 0.6317585110664368)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ['what', 'was', 'the', 'immediate', 'impact', 'of', 'the', 'success', 'of', 'the', 'manhattan', 'project']\n",
      "\n",
      "Document: 1 The Giant Sequoia named The General Sherman Tree reigns supreme as the largest of the living things on earth. 2  This tree is so large that it's seemingly small growth rate of only one millimeter per year yields a volume of new wood equal to that of all the wood found in a 50 foot tree! Since there is an average of 200 seeds per cone, 400,000 seeds could be released from each tree each year. 2  With an average of three mature trees per acre, over a million seeds are produced per acre per year in most Sequoia groves. 3  Giant Sequoias can provide food for themselves (and others).\n",
      "Document ID: 6550119\n",
      "Similarity: 0.6452532410621643\n",
      "-------------------------------------------\n",
      "Document: Basic Skills For Kids (KIM-9117CD) by William Janiak is an enticing collection of fun and educational songs aimed at teaching a child a solid understanding of body part identification, motor development, right-left discrimination, and emotional awareness throughout its six-track playlist, doubled with instrumentals of the first six: I've Got Parts In The Middle Of My Body; The Pencil Song; Today I'm Happy; Moving; I'm A Helper; and Two By Two.\n",
      "Document ID: 2468422\n",
      "Similarity: 0.6444576382637024\n",
      "-------------------------------------------\n",
      "Document: Manhattan Project. 1  The Manhattan Project was a secret military project created in 1942 to produce the first US nuclear weapon. Fears that Nazi Germany would build and use a nuclear weapon during World War II triggered the start of the Manhattan Project, which was originally based in Manhattan, New York.\n",
      "Document ID: 3607205\n",
      "Similarity: 0.6429510712623596\n",
      "-------------------------------------------\n",
      "Document: electroform; electroforming; electrogasdynamics; electrogastrogram; electrogastrograph; electrogen\n",
      "Document ID: 8801756\n",
      "Similarity: 0.6416457891464233\n",
      "-------------------------------------------\n",
      "Document: Area code 646 covers Manhattan, New York City. Manhattan is also covered by area code 212 and area code 917. New York has area codes of 212, 315, 347, 516, 518, 585, 607, 631, 646, 716, 718, 845, 914, 917, 929.\n",
      "Document ID: 4028478\n",
      "Similarity: 0.6410707831382751\n",
      "-------------------------------------------\n",
      "Document: The Bordetella vaccine is administered together with the other core vaccines and it may take up to 7 days before the vaccine will be effective, so make sure you plan ahead if you intend to take part in shows or take your pet to a daycare.\n",
      "Document ID: 5021412\n",
      "Similarity: 0.6367886066436768\n",
      "-------------------------------------------\n",
      "Document: Hilton Baltimore. The Hilton Baltimore is a 757âroom hotel located on West Pratt Street in Baltimore, Maryland, United States. Initially proposed in 2003, actual construction of the city-owned venture took place between 2006 and 2008 as part of the Baltimore Convention Center.\n",
      "Document ID: 7579485\n",
      "Similarity: 0.6362625360488892\n",
      "-------------------------------------------\n",
      "Document: One promising opportunity for healthcare nonprofits is in the area of fund development. Many nonprofit hospitals and healthcare facilities have focused their fundraising efforts on planning and constructing buildings.\n",
      "Document ID: 732578\n",
      "Similarity: 0.6349706649780273\n",
      "-------------------------------------------\n",
      "Document: Vaporpressureofammonia(degreescentigrade,mmofmercury andatmospheres) ^^ 2.Vaporpressureofammonia(degreesFahrenheit,poundsper squareinchandatmospheres) 34 3.Rateofchangeofvaporpressurewithtemperature(-^j 35 I.INTRODUCTION Themeasurementspresentedinthispaperformaportionofthe workundertakenbytheBureauofStandardsinthedetermination\n",
      "Document ID: 7210329\n",
      "Similarity: 0.6323652267456055\n",
      "-------------------------------------------\n",
      "Document: But a catastrophic plunge in the countryâs birthrateâa problem plaguing many of the worldâs affluent economiesâcould undermine Singaporeâs success.\n",
      "Document ID: 759877\n",
      "Similarity: 0.6317585110664368\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f'Query: {query}')\n",
    "print()\n",
    "for doc_id, score in sims:\n",
    "    print(f'Document: {corpus_df.iloc[doc_id][\"text\"]}')\n",
    "    print(f'Document ID: {corpus_df.index.values[doc_id]}')\n",
    "    print(f'Similarity: {score}')\n",
    "    print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
