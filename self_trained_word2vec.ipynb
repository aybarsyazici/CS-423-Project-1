{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import helpers\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import multiprocessing as mp\n",
    "import os \n",
    "import math\n",
    "from functools import partial\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short, stem_text\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# Load the data from files\n",
    "with open(f'{DATA_DIR}/corpus.jsonl', 'r') as f:\n",
    "    corpus_data = {int(item['_id']): item['text'] for item in (json.loads(line) for line in f)}\n",
    "\n",
    "with open(f'{DATA_DIR}/queries.jsonl', 'r') as f:\n",
    "    queries_data = {int(item['_id']): item['text'] for item in (json.loads(line) for line in f)}\n",
    "\n",
    "train_data = pd.read_csv(f'{DATA_DIR}/task1_train.tsv', delimiter='\\t')\n",
    "test_data = pd.read_csv(f'{DATA_DIR}/task1_test.tsv', delimiter='\\t')\n",
    "\n",
    "# Make sure that the document_id and query_id are int64\n",
    "train_data['corpus-id'] = train_data['corpus-id'].astype('int64')\n",
    "train_data['query-id'] = train_data['query-id'].astype('int64')\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation, lambda x: strip_short(s=x,minsize=1), strip_multiple_whitespaces, remove_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df from the corpus data\n",
    "corpus_df = pd.DataFrame.from_dict(corpus_data, orient='index', columns=['text'])\n",
    "# Create a df from the queries data\n",
    "queries_df = pd.DataFrame.from_dict(queries_data, orient='index', columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>[1396701, 1396704, 1396705, 1396707, 1396708, ...</td>\n",
       "      <td>[0, 0, 1, 0, 2, 0, 3, 0, 0, 0, 2, 1, 2, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146187</td>\n",
       "      <td>[1028971, 1028972, 1131101, 1138801, 1230566, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1114646</td>\n",
       "      <td>[1002453, 1216492, 1316103, 1316109, 1342262, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1129237</td>\n",
       "      <td>[1020793, 1128332, 1138726, 1169301, 120308, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 3, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>573724</td>\n",
       "      <td>[1005338, 104856, 1053303, 1165128, 1165129, 1...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>148538</td>\n",
       "      <td>[1299824, 1299830, 1311202, 1311204, 1311206, ...</td>\n",
       "      <td>[2, 1, 2, 1, 0, 1, 1, 2, 1, 2, 2, 2, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>527433</td>\n",
       "      <td>[1000485, 1101462, 1187918, 1212778, 1212782, ...</td>\n",
       "      <td>[3, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130510</td>\n",
       "      <td>[1046258, 1110766, 1156210, 1159414, 1211365, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>405717</td>\n",
       "      <td>[1111371, 1111372, 1111375, 1538943, 1538949, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1106007</td>\n",
       "      <td>[1020463, 1040867, 1195441, 1334328, 1334330, ...</td>\n",
       "      <td>[1, 0, 0, 2, 3, 2, 0, 2, 3, 3, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id                                          corpus-id  \\\n",
       "0    915593  [1396701, 1396704, 1396705, 1396707, 1396708, ...   \n",
       "1    146187  [1028971, 1028972, 1131101, 1138801, 1230566, ...   \n",
       "2   1114646  [1002453, 1216492, 1316103, 1316109, 1342262, ...   \n",
       "3   1129237  [1020793, 1128332, 1138726, 1169301, 120308, 1...   \n",
       "4    573724  [1005338, 104856, 1053303, 1165128, 1165129, 1...   \n",
       "5    148538  [1299824, 1299830, 1311202, 1311204, 1311206, ...   \n",
       "6    527433  [1000485, 1101462, 1187918, 1212778, 1212782, ...   \n",
       "7    130510  [1046258, 1110766, 1156210, 1159414, 1211365, ...   \n",
       "8    405717  [1111371, 1111372, 1111375, 1538943, 1538949, ...   \n",
       "9   1106007  [1020463, 1040867, 1195441, 1334328, 1334330, ...   \n",
       "\n",
       "                                               score  \n",
       "0  [0, 0, 1, 0, 2, 0, 3, 0, 0, 0, 2, 1, 2, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 3, 0, ...  \n",
       "4  [1, 1, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, ...  \n",
       "5  [2, 1, 2, 1, 0, 1, 1, 2, 1, 2, 2, 2, 0, 1, 1, ...  \n",
       "6  [3, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 3, ...  \n",
       "7  [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 2, ...  \n",
       "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "9  [1, 0, 0, 2, 3, 2, 0, 2, 3, 3, 1, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_2 = pd.read_csv(f'{DATA_DIR}/task2_train.tsv', delimiter='\\t')\n",
    "train_data_2['corpus-id'] = train_data_2['corpus-id'].apply(lambda x: eval(x))\n",
    "train_data_2['query-id'] = train_data_2['query-id'].astype('int64')\n",
    "train_data_2['score'] = train_data_2['score'].apply(lambda x: eval(x))\n",
    "train_data_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2 = train_data_2.explode(['corpus-id', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1543, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max score: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>1396701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>1396704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>1396705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>1396707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>1396708</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>1453630</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>1605506</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>1652605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>1772930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>915593</td>\n",
       "      <td>1772932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id corpus-id score\n",
       "0    915593   1396701     0\n",
       "0    915593   1396704     0\n",
       "0    915593   1396705     1\n",
       "0    915593   1396707     0\n",
       "0    915593   1396708     2\n",
       "0    915593   1453630     0\n",
       "0    915593   1605506     3\n",
       "0    915593   1652605     0\n",
       "0    915593   1772930     0\n",
       "0    915593   1772932     0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train_data_2.shape)\n",
    "print('Max score:', train_data_2['score'].max())\n",
    "train_data_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write train_data_2 to a csv file\n",
    "train_data_2.to_csv(f'{DATA_DIR}/my_custom_train_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1185869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1185868</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>597651</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403613</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1183785</td>\n",
       "      <td>389</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>312651</td>\n",
       "      <td>616</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80385</td>\n",
       "      <td>723</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>645590</td>\n",
       "      <td>944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>645337</td>\n",
       "      <td>1054</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>186154</td>\n",
       "      <td>1160</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id  corpus-id  score\n",
       "0   1185869          0      3\n",
       "1   1185868         16      3\n",
       "2    597651         49      3\n",
       "3    403613         60      3\n",
       "4   1183785        389      3\n",
       "5    312651        616      3\n",
       "6     80385        723      3\n",
       "7    645590        944      3\n",
       "8    645337       1054      3\n",
       "9    186154       1160      3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the scores of train_data with 3\n",
    "train_data['score'] = 3\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534294, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat train_data rows and train_data_2 rows, remove duplicate (query-id, corpus-id) pairs\n",
    "train_data = pd.concat([train_data, train_data_2], axis=0)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop_duplicates(subset=['query-id', 'corpus-id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1185869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1185868</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>597651</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403613</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1183785</td>\n",
       "      <td>389</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>312651</td>\n",
       "      <td>616</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80385</td>\n",
       "      <td>723</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>645590</td>\n",
       "      <td>944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>645337</td>\n",
       "      <td>1054</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>186154</td>\n",
       "      <td>1160</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id corpus-id score\n",
       "0   1185869         0     3\n",
       "1   1185868        16     3\n",
       "2    597651        49     3\n",
       "3    403613        60     3\n",
       "4   1183785       389     3\n",
       "5    312651       616     3\n",
       "6     80385       723     3\n",
       "7    645590       944     3\n",
       "8    645337      1054     3\n",
       "9    186154      1160     3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_data to a csv file\n",
    "train_data.to_csv(f'{DATA_DIR}/cross_encoder_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534294, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1185869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1185868</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>597651</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403613</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1183785</td>\n",
       "      <td>389</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>312651</td>\n",
       "      <td>616</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80385</td>\n",
       "      <td>723</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>645590</td>\n",
       "      <td>944</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>645337</td>\n",
       "      <td>1054</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>186154</td>\n",
       "      <td>1160</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id corpus-id score  relevant\n",
       "0   1185869         0     3         1\n",
       "1   1185868        16     3         1\n",
       "2    597651        49     3         1\n",
       "3    403613        60     3         1\n",
       "4   1183785       389     3         1\n",
       "5    312651       616     3         1\n",
       "6     80385       723     3         1\n",
       "7    645590       944     3         1\n",
       "8    645337      1054     3         1\n",
       "9    186154      1160     3         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data['relevant'] = train_data['score'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1867825</th>\n",
       "      <td>After the invention of the cotton gin, cotton ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419610</th>\n",
       "      <td>Timer has separate night and day outlets, whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614226</th>\n",
       "      <td>The rose-buying public still encounters a wide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108603</th>\n",
       "      <td>Map of Wendover (Aut) Airport. A detailed map ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744854</th>\n",
       "      <td>And as the poems Reapers and Cotton Song indic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7962609</th>\n",
       "      <td>Top 10 facts about the world. Oxycodone is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864307</th>\n",
       "      <td>One of the benefits of Vitex Chasteberry Tree ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667700</th>\n",
       "      <td>1 The frequency of the recessive allele. 2  An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620277</th>\n",
       "      <td>Queen of the mountains. The Rigi mountain is p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701619</th>\n",
       "      <td>- summary of Bluetooth network configurations ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1471406 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "1867825  After the invention of the cotton gin, cotton ...\n",
       "419610   Timer has separate night and day outlets, whic...\n",
       "4614226  The rose-buying public still encounters a wide...\n",
       "4108603  Map of Wendover (Aut) Airport. A detailed map ...\n",
       "3744854  And as the poems Reapers and Cotton Song indic...\n",
       "...                                                    ...\n",
       "7962609  Top 10 facts about the world. Oxycodone is an ...\n",
       "7864307  One of the benefits of Vitex Chasteberry Tree ...\n",
       "7667700  1 The frequency of the recessive allele. 2  An...\n",
       "4620277  Queen of the mountains. The Rigi mountain is p...\n",
       "5701619  - summary of Bluetooth network configurations ...\n",
       "\n",
       "[1471406 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows=> 517893\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 3. Picture This!Photo-based writing can be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acxiom Corporation is a marketing technology a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How much do wound, ostomy, and continence nurs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cold fronts produce most of the severe weather...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typical costs: Charges for the use of a hearse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  1 3. Picture This!Photo-based writing can be a...\n",
       "1  Acxiom Corporation is a marketing technology a...\n",
       "2  How much do wound, ostomy, and continence nurs...\n",
       "3  Cold fronts produce most of the severe weather...\n",
       "4  Typical costs: Charges for the use of a hearse..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_corpus(result, original_df, id='corpus-id'):\n",
    "    unique_docid=result[id].unique()\n",
    "    condition=original_df.index.isin(unique_docid)\n",
    "    corpus=original_df[condition].reset_index(drop=True)\n",
    "    print('Number of Rows=>',len(corpus))\n",
    "    return corpus\n",
    "\n",
    "training_corpus=create_corpus(train_data, corpus_df)\n",
    "training_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e3bfe4b2f24816b1d331827dcfc288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/517893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Lowercasing the text\n",
    "training_corpus['cleaned']=training_corpus['text'].apply(lambda x:x.lower())\n",
    "tqdm.pandas()\n",
    "\n",
    "# Dictionary of english Contractions\n",
    "contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\"can't\": \"can not\",\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\"i'll\": \"i will\",\"i'll've\": \"i will have\",\"i'm\": \"i am\",\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\"it'll've\": \"it will have\",\n",
    "\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"that'd\": \"that would\",\"that'd've\": \"that would have\",\n",
    "\"there'd\": \"there would\",\"there'd've\": \"there would have\",\n",
    "\"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\"what're\": \"what are\",\n",
    "\"what've\": \"what have\",\"when've\": \"when have\",\"where'd\": \"where did\",\n",
    "\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n",
    "\"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\"you'd've\": \"you would have\",\"you'll\": \"you will\",\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\"you've\": \"you have\"}\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "# Function for expanding contractions\n",
    "def expand_contractions(text,contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "# Expanding Contractions\n",
    "training_corpus['cleaned']=training_corpus['cleaned'].progress_apply(lambda x:expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Cleaning Text\n",
    "def clean_text(text):\n",
    "    text=re.sub('\\w*\\d\\w*','', text)\n",
    "    text=re.sub('\\n',' ',text)\n",
    "    text=re.sub(r\"http\\S+\", \"\", text)\n",
    "    text=re.sub('[^a-z]',' ',text)\n",
    "    return text\n",
    " \n",
    "# Cleaning corpus using RegEx\n",
    "training_corpus['cleaned']=training_corpus['cleaned'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing extra spaces\n",
    "training_corpus['cleaned']=training_corpus['cleaned'].apply(lambda x: re.sub(' +',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14859ab0e79f42cfb2493993ff07d728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/517893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stopwords removal & Lemmatizing tokens using SpaCy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm',disable=['ner','parser'])\n",
    "nlp.max_length=5000000\n",
    "\n",
    "# Removing Stopwords and Lemmatizing words\n",
    "training_corpus['lemmatized']=training_corpus['cleaned'].progress_apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_corpus['cleaned']=training_corpus['text'].apply(lambda x:preprocess_string(x,CUSTOM_FILTERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows=> 502949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>)what was the immediate impact of the success ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_________ justice is designed to repair the ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what color is amber urine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is autoimmune hepatitis a bile acid synthesis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elegxo meaning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  )what was the immediate impact of the success ...\n",
       "1  _________ justice is designed to repair the ha...\n",
       "2                          what color is amber urine\n",
       "3  is autoimmune hepatitis a bile acid synthesis ...\n",
       "4                                     elegxo meaning"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_queries=create_corpus(train_data, queries_df, id='query-id')\n",
    "training_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing the text\n",
    "training_queries['cleaned']=training_queries['query'].apply(lambda x:x.lower())\n",
    "\n",
    "# Expanding contractions\n",
    "training_queries['cleaned']=training_queries['cleaned'].apply(lambda x:expand_contractions(x))\n",
    "\n",
    "# Cleaning queries using RegEx\n",
    "training_queries['cleaned']=training_queries['cleaned'].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Removing extra spaces\n",
    "training_queries['cleaned']=training_queries['cleaned'].apply(lambda x: re.sub(' +',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training=pd.concat([training_corpus.rename(columns={'lemmatized':'text'})['text'],\\\n",
    "                             training_queries.rename(columns={'cleaned':'text'})['text']])\\\n",
    "                             .sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Creating data for the model training\n",
    "train_data=[]\n",
    "for i in combined_training:\n",
    "    train_data.append(i.split())\n",
    "\n",
    "# Training a word2vec model from the given data set\n",
    "w2v_model = Word2Vec(train_data, size=300, min_count=2,window=5, sg=1,workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
