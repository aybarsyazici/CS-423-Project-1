{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import helpers\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import multiprocessing as mp\n",
    "import os \n",
    "import math\n",
    "from functools import partial\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# Load the data from files\n",
    "with open(f'{DATA_DIR}/corpus.jsonl', 'r') as f:\n",
    "    corpus_data = {int(item['_id']): item['text'] for item in (json.loads(line) for line in f)}\n",
    "\n",
    "with open(f'{DATA_DIR}/queries.jsonl', 'r') as f:\n",
    "    queries_data = {int(item['_id']): item['text'] for item in (json.loads(line) for line in f)}\n",
    "\n",
    "train_data = pd.read_csv(f'{DATA_DIR}/task1_train.tsv', delimiter='\\t')\n",
    "test_data = pd.read_csv(f'{DATA_DIR}/task1_test.tsv', delimiter='\\t')\n",
    "\n",
    "# Rename corpus-id to document_id and query-id to query_id in both train and test data\n",
    "train_data = train_data.rename(columns={'corpus-id': 'document_id', 'query-id': 'query_id'})\n",
    "test_data = test_data.rename(columns={'corpus-id': 'document_id', 'query-id': 'query_id'})\n",
    "# Make sure that the document_id and query_id are int64\n",
    "train_data['document_id'] = train_data['document_id'].astype('int64')\n",
    "train_data['query_id'] = train_data['query_id'].astype('int64')\n",
    "\n",
    "# Create a df from the corpus data\n",
    "corpus_df = pd.DataFrame.from_dict(corpus_data, orient='index', columns=['text'])\n",
    "# Create a df from the queries data\n",
    "queries_df = pd.DataFrame.from_dict(queries_data, orient='index', columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = corpus_df['text'].tolist()\n",
    "queries = queries_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6604e07032094bc58292aab2e4cb18e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a8e1d/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0d25b4fe5146599ece1e3c4f4a76a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645ccada27c24355934cb6fd0ede8143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b20bca8e1d/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55be61c9e55a4553a8178c126a5138dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0bca8e1d/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36b834f35b64e498fc7fa1d1fa31159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320c5ff448134cd5a4a54192d619841e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e1d/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e04b6339a514e44b0e10146f30936b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c33373695447c5b8a8f65061fe1429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4f7ac459c4464881826944d12d5f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac6d70b02d64458ad61f120012727c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)a8e1d/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817dc8a0f7c744f29b0dd4cdd7070938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb643bd0f564ddbbc227499ab2651ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)8e1d/train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f2d5724fb941ecb8982ade14ff17a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b20bca8e1d/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fc437811e142398830e80ec4e120ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bca8e1d/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d2ef83e8fc4958b2ee7defb80462e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/45982 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/aybars/CS-423-Project-1/sentence-transformer.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aybars/CS-423-Project-1/sentence-transformer.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m document_embeddings \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencode(documents, show_progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aybars/CS-423-Project-1/sentence-transformer.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# write to pickle file\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aybars/CS-423-Project-1/sentence-transformer.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m os\u001b[39m.\u001b[39;49mopen(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mDATA_DIR\u001b[39m}\u001b[39;49;00m\u001b[39m/bert_document_embeddings.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aybars/CS-423-Project-1/sentence-transformer.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(document_embeddings, f)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# check if bert_document_embeddings.pkl file exists\n",
    "import pickle\n",
    "if os.path.isfile(f'{DATA_DIR}/bert_document_embeddings.pkl'):\n",
    "    document_embeddings = pickle.load(f'{DATA_DIR}/bert_document_embeddings.pkl')\n",
    "else:\n",
    "    document_embeddings = model.encode(documents, show_progress_bar=True)\n",
    "    # write document embeddings to file\n",
    "    with open(f'{DATA_DIR}/bert_document_embeddings.pkl', 'wb') as f:\n",
    "        pickle.dump(document_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1d1c37000d4e579e765f69916f5ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the first query\n",
    "query_embedding = model.encode(queries[0], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "# compute cosine similarity\n",
    "# query_embedding to tensor\n",
    "query_embedding = torch.tensor(query_embedding)\n",
    "query_embedding = query_embedding.to('cuda')\n",
    "cos_scores = util.cos_sim(query_embedding.reshape(1,-1), document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1471406, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# get the top 10 documents\n",
    "top_results = torch.topk(cos_scores, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document id 0\n",
      "The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was. The only cloud hanging over the impressive achievement of the atomic researchers and engineers is what their success truly meant; hundreds of thousands of innocent lives obliterated.\n",
      "Similarity score: 0.6887286901473999\n",
      "________________________\n",
      "\n",
      "Document id 2422197\n",
      "President Harry Truman learns the full details of the Manhattan Project, in which scientists are attempting to create the first atomic bomb, on this day in 1945. The information thrust upon Truman a momentous decision: whether or not to use the worldâs first weapon of mass destruction.\n",
      "Similarity score: 0.6863462924957275\n",
      "________________________\n",
      "\n",
      "Document id 2681219\n",
      "President Harry Truman learns the full details of the Manhattan Project, in which scientists are attempting to create the first atomic bomb, on this day in 1945.The information thrust upon Truman a momentous decision: whether or not to use the worldâs first weapon of mass destruction.resident Harry Truman learns the full details of the Manhattan Project, in which scientists are attempting to create the first atomic bomb, on this day in 1945.\n",
      "Similarity score: 0.6750324964523315\n",
      "________________________\n",
      "\n",
      "Document id 2395244\n",
      "The Manhattan Project was the government project that took place from 1942 to 1946, the purpose of which was to develop a nuclear bomb. It succeeded on 16 July 1945 at the Trinity Test in New Mexico and went on to produce the two atomic bombs that destroyed the Japanese cities of Hiroshima and Nagasaki during WWII.\n",
      "Similarity score: 0.6746104955673218\n",
      "________________________\n",
      "\n",
      "Document id 6108324\n",
      "The Manhattan Project. The Manhattan Project was a research and development program, led by the United States with participation from the United Kingdom and Canada, that produced the first atomic bomb during World War II. It was also charged with gathering intelligence on the German nuclear energy project.\n",
      "Similarity score: 0.6640629768371582\n",
      "________________________\n",
      "\n",
      "Document id 7807054\n",
      "The text for this section was adapted from the History Division, now Office of History and Heritage Resources, publication: F. G. Gosling, The Manhattan Project: Making the Atomic Bomb (DOE/MA-0001; Washington: History Division, Department of Energy, January 1999).\n",
      "Similarity score: 0.6601147055625916\n",
      "________________________\n",
      "\n",
      "Document id 4138462\n",
      "The Manhattan Project was a secret military project created in 1942 to produce the first US nuclear weapon. Fears that Nazi Germany would build and use a nuclear weapon during World War II triggered the start of the Manhattan Project, which was originally based in Manhattan, New York.\n",
      "Similarity score: 0.6327992677688599\n",
      "________________________\n",
      "\n",
      "Document id 2148554\n",
      "This article is about the atomic bomb project. For other uses, see Manhattan Project (disambiguation). The Manhattan Project was a research and development undertaking during World War II that produced the first nuclear weapons. It was led by the United States with the support of the United Kingdom and Canada.\n",
      "Similarity score: 0.6251473426818848\n",
      "________________________\n",
      "\n",
      "Document id 3471264\n",
      "This article is about the atomic bomb project. For other uses, see Manhattan Project (disambiguation). The Manhattan Project was a research and development project that produced the first nuclear weapons during World War II. It was led by the United States with the support of the United Kingdom and Canada. From 1942 to 1946, the project was under the direction of Major General Leslie Groves of the U.S. Army Corps of Engineers; physicist J. Robert Oppenheimer was the director of the Los Alamos Laboratory that designed the actual bombs.\n",
      "Similarity score: 0.6203194856643677\n",
      "________________________\n",
      "\n",
      "Document id 2395252\n",
      "The Manhattan project was an initiative undertaken by president Franklin Roosevelt, to build an atomic bomb. It was going to be used against Nazi Germany, supposedly only if they developed nuclear weapons (which of course was a a great fear at the time).\n",
      "Similarity score: 0.6181391477584839\n",
      "________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for top_k_id in top_results[1][0]:\n",
    "    top_k_id = top_k_id.item()\n",
    "    document_id = corpus_df.iloc[top_k_id].name\n",
    "    print(f'Document id {document_id}')\n",
    "    print(f'{corpus_df.loc[document_id].text}')\n",
    "    print(f'Similarity score: {cos_scores[0][top_k_id]}')\n",
    "    print('________________________')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c8d770aa9340da94efd73864491e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task1_matrix = np.zeros((len(test_data), document_embeddings.shape[1]))\n",
    "\n",
    "for index, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "    query = queries_df.loc[row['query_id']]['text']\n",
    "    query_vector = model.encode(query, show_progress_bar=False, device='cuda', convert_to_tensor=True)\n",
    "    task1_matrix[index] = query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert document_embeddings & task1 matrix to torch tensors\n",
    "document_embeddings = torch.tensor(document_embeddings)\n",
    "task1_matrix = torch.tensor(task1_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = document_embeddings.to('cuda')\n",
    "task1_matrix = task1_matrix.to('cuda')\n",
    "\n",
    "# convert both matrices to float\n",
    "document_embeddings = document_embeddings.float()\n",
    "task1_matrix = task1_matrix.float()\n",
    "\n",
    "task1_results = util.semantic_search(query_embeddings=task1_matrix, corpus_embeddings=document_embeddings, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e70e91578f4a18b8e2e69f0b23b788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task1_results_final = []\n",
    "for results in tqdm(task1_results):\n",
    "    temp = []\n",
    "    for result in results:\n",
    "        document_id = corpus_df.iloc[result['corpus_id']].name\n",
    "        temp.append(document_id)\n",
    "    task1_results_final.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7067032,\n",
       " 4107182,\n",
       " 2495755,\n",
       " 3289525,\n",
       " 4381656,\n",
       " 7067034,\n",
       " 3305011,\n",
       " 793633,\n",
       " 689657,\n",
       " 3557087]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_results_final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load task2 test data\n",
    "test_data2 = pd.read_csv(f'{DATA_DIR}/task2_test.tsv', delimiter='\\t')\n",
    "test_data2['corpus-id'] = test_data2['corpus-id'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54c8a50af2a481da5bf66c461f6315f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52f491378c1450c8cf46a7fac0bb131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fd57336aff41d1a7351b62615800be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2055f7e5494aa4a9998a513989a52f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12d9abac1594dcda2eee67965c2677e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# We use a cross-encoder, to re-rank\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e99f8656ee4da79af81bc6bbb5ef03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iterate row by row\n",
    "task2_results = []\n",
    "for index, row in tqdm(test_data2.iterrows(), total=len(test_data2)):\n",
    "    query = queries_df.loc[row['query-id']]['text']\n",
    "    question_embedding = model.encode(query, show_progress_bar=False, device='cuda', convert_to_tensor=True)\n",
    "    question_embedding = question_embedding.cuda()\n",
    "\n",
    "    hits = row['corpus-id']\n",
    "\n",
    "    cross_inp = [[query, corpus_df.loc[hit].text] for hit in hits]\n",
    "    cross_scores = cross_encoder.predict(cross_inp)\n",
    "    # make all the scores positive\n",
    "    cross_scores = [math.exp(score) for score in cross_scores]\n",
    "\n",
    "    task2_results.append(cross_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a csv file for submission\n",
    "# HEADER: id,corpus-id,score\n",
    "# task1 results will be: query-id,[corpus-id1, corpus-id2, ...] (top 10 corpus-ids), -1\n",
    "# task2 results will be query-id, -1, [score1, score2...] \n",
    "# create the file\n",
    "\n",
    "with open(f'{DATA_DIR}/sentence-transformers_submission.csv', 'w') as f:\n",
    "    id = 0\n",
    "    f.writelines('id,corpus-id,score\\n')\n",
    "    for i, row in enumerate(task1_results_final):\n",
    "        to_write = \"\\\"[\"\n",
    "        for j, corpus_id in enumerate(row):\n",
    "            if j != len(row)-1:\n",
    "                to_write += str(corpus_id) + \", \"\n",
    "            else:\n",
    "                to_write += str(corpus_id)\n",
    "        to_write += \"]\\\"\"\n",
    "        f.write(str(id) + \",\" + to_write + \",-1\\n\")\n",
    "        id += 1\n",
    "\n",
    "    for i,row in enumerate(task2_results):\n",
    "        query_id_to_write = test_data2.iloc[i]['query-id']\n",
    "        to_write = \"\\\"[\"\n",
    "        for j, score in enumerate(row):\n",
    "            if j != len(row)-1:\n",
    "                to_write += str(score) + \", \"\n",
    "            else:\n",
    "                to_write += str(score) \n",
    "        to_write += \"]\\\"\"\n",
    "        f.write(str(id) + \",-1,\" + to_write + \"\\n\")\n",
    "        id += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
