{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import helpers\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import multiprocessing as mp\n",
    "import os \n",
    "import math\n",
    "from functools import partial\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# Load the data from files\n",
    "with open(f'{DATA_DIR}/corpus.jsonl', 'r') as f:\n",
    "    corpus_data = {int(item['_id']): item['text'] for item in (json.loads(line) for line in f)}\n",
    "\n",
    "with open(f'{DATA_DIR}/queries.jsonl', 'r') as f:\n",
    "    queries_data = {int(item['_id']): item['text'] for item in (json.loads(line) for line in f)}\n",
    "\n",
    "train_data = pd.read_csv(f'{DATA_DIR}/task1_train.tsv', delimiter='\\t')\n",
    "test_data = pd.read_csv(f'{DATA_DIR}/task1_test.tsv', delimiter='\\t')\n",
    "\n",
    "# Rename corpus-id to document_id and query-id to query_id in both train and test data\n",
    "train_data = train_data.rename(columns={'corpus-id': 'document_id', 'query-id': 'query_id'})\n",
    "test_data = test_data.rename(columns={'corpus-id': 'document_id', 'query-id': 'query_id'})\n",
    "# Make sure that the document_id and query_id are int64\n",
    "train_data['document_id'] = train_data['document_id'].astype('int64')\n",
    "train_data['query_id'] = train_data['query_id'].astype('int64')\n",
    "\n",
    "# Create a df from the corpus data\n",
    "corpus_df = pd.DataFrame.from_dict(corpus_data, orient='index', columns=['text'])\n",
    "# Create a df from the queries data\n",
    "queries_df = pd.DataFrame.from_dict(queries_data, orient='index', columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = corpus_df['text'].tolist()\n",
    "queries = queries_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if bert_document_embeddings.pkl file exists\n",
    "import torch\n",
    "if os.path.isfile(f'{DATA_DIR}/bert_document_embeddings.pt'):\n",
    "    document_embeddings = torch.load(f'{DATA_DIR}/bert_document_embeddings.pt')\n",
    "else:\n",
    "    document_embeddings = model.encode(documents, show_progress_bar=True)\n",
    "    # write document embeddings to file\n",
    "    torch.save(document_embeddings, f'{DATA_DIR}/bert_document_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0343,  0.0368,  0.0100,  ..., -0.0328, -0.0123, -0.0185],\n",
       "        [-0.0350, -0.0376, -0.0377,  ..., -0.0182, -0.0011,  0.0298],\n",
       "        [ 0.0097, -0.0118, -0.0038,  ...,  0.0081,  0.0623,  0.0534],\n",
       "        ...,\n",
       "        [-0.0496, -0.0663, -0.0232,  ...,  0.0189, -0.0258, -0.0463],\n",
       "        [-0.0100, -0.0372, -0.0377,  ...,  0.0322,  0.0201, -0.0065],\n",
       "        [ 0.0279, -0.0921,  0.0161,  ..., -0.0238,  0.0662,  0.0137]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b142ee2ae54befa8eef7341f5ec23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# task1_matrix = np.zeros((len(test_data), document_embeddings.shape[1]))\n",
    "# create tensor of shape (len(test_data), document_embeddings.shape[1])\n",
    "task1_matrix = torch.zeros((len(test_data), document_embeddings.shape[1])).to('cuda')\n",
    "for index, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "    query = queries_df.loc[row['query_id']]['text']\n",
    "    query_vector = model.encode(query, show_progress_bar=False, device='cuda', convert_to_tensor=True)\n",
    "    task1_matrix[index] = query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "# document_embeddings = document_embeddings.to('cuda')\n",
    "# task1_matrix = task1_matrix.to('cuda')\n",
    "\n",
    "# # convert both matrices to float\n",
    "# document_embeddings = document_embeddings.float()\n",
    "# task1_matrix = task1_matrix.float()\n",
    "\n",
    "task1_results = util.semantic_search(query_embeddings=task1_matrix, corpus_embeddings=document_embeddings, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6dfce1e6d14f88bec32ed6954b8dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7437 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task1_results_final = []\n",
    "for results in tqdm(task1_results):\n",
    "    temp = []\n",
    "    for result in results:\n",
    "        document_id = corpus_df.iloc[result['corpus_id']].name\n",
    "        temp.append(document_id)\n",
    "    task1_results_final.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7067032,\n",
       " 4107182,\n",
       " 2495755,\n",
       " 3289525,\n",
       " 4381656,\n",
       " 7067034,\n",
       " 3305011,\n",
       " 793633,\n",
       " 689657,\n",
       " 3557087]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1_results_final[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load task2 test data\n",
    "test_data2 = pd.read_csv(f'{DATA_DIR}/task2_test.tsv', delimiter='\\t')\n",
    "test_data2['corpus-id'] = test_data2['corpus-id'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load my training data to train a custom CrossEncoder\n",
    "my_train_data = pd.read_csv(f'{DATA_DIR}/my_custom_train_data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join train_data2 with corpus_df to get the text of the documents\n",
    "my_train_data = my_train_data.join(corpus_df, on='corpus-id', how='left', rsuffix='_corpus')\n",
    "# rename text column to corpus_text\n",
    "my_train_data = my_train_data.rename(columns={'text': 'corpus_text'})\n",
    "# join with queries_df to get the text of the queries\n",
    "my_train_data = my_train_data.join(queries_df, on='query-id', how='left', rsuffix='_query')\n",
    "# rename text column to query_text\n",
    "my_train_data = my_train_data.rename(columns={'text': 'query_text'})\n",
    "my_train_data['score'] = my_train_data['score'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "0    980\n",
       "1    306\n",
       "2    185\n",
       "3     72\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_train_data.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467545d286254f8aa7539c99bc290a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import InputExample\n",
    "# Create trainining examples\n",
    "training_examples = [\n",
    "    InputExample(\n",
    "        texts=[row['query_text'], row['corpus_text']], label=row['score']\n",
    "    ) for index, row in tqdm(my_train_data.iterrows())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_encoder = CrossEncoder('sentence-transformers/all-mpnet-base-v2', num_labels=1, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e990a7fdced74df691cdc3d941555977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8e2a7f4b37404bb3b20225e346468f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43750391158a47c483ee88728faf5f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087dbdab1d2f47eabce33816253a7255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f06ae7d0fd94159bf93efa33ac69635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832dfe0f1baa4013a4fe4e4e2fe159d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c353cb1b2f54c1ea025b03627571ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388796f93ac94ee6b3b0259f93d34c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858abf68d24a47ca9f8fe2b073ce6d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660576a15fcf4ccb9a93c721b2ed556d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832650e402a04cf98967623bcdefb6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1490e0955d5343b19568d18393b19a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77f835f1e2b4338858243128ff32f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cd9318abf34c6a9e3500430bf60c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a207c201ff68435a98629f446bb0e5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c7cca4eb344f0e84c43e749938a4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5868f7163c4c5d8b72701e481fb9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd27d7dba3f54cb7aeb81d99e7f92d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce7a664f9fe429e85e74700c318d121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea725a4f7f94e308719c241111f2d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da49755d5af74fb0929fe7399cdb9221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "# Create a dataloader\n",
    "train_dataloader = DataLoader(training_examples, shuffle=True, batch_size=32)\n",
    "num_epochs = 20\n",
    "# We add an evaluator, which evaluates the performance during training\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)\n",
    "cross_encoder.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=f'{DATA_DIR}/cross_encoder_model3',\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder.save(f'{DATA_DIR}/cross_encoder_model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8304611841498001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = CECorrelationEvaluator.from_input_examples(examples=training_examples, name='my_custom_test_data2')\n",
    "evaluator(cross_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import util\n",
    "\n",
    "# # iterate row by row\n",
    "# task2_results = []\n",
    "# for index, row in tqdm(test_data2.iterrows(), total=len(test_data2)):\n",
    "#     query = queries_df.loc[row['query-id']]['text']\n",
    "#     question_embedding = model.encode(query, show_progress_bar=False, device='cuda', convert_to_tensor=True)\n",
    "#     doc_list = row['corpus-id']\n",
    "#     # convert doc_list from doc ids to doc indexes\n",
    "#     doc_list = [corpus_df.index.get_loc(doc_id) for doc_id in doc_list]\n",
    "#     doc_embeds = document_embeddings[doc_list]\n",
    "#     # find cosine similarity between question_embedding and doc_embeddings\n",
    "#     cos_scores = util.cos_sim(question_embedding, doc_embeds)\n",
    "#     # make all the scores positive and append to task2_results\n",
    "#     task2_results.append([math.exp(score) for score in cos_scores[0]])\n",
    "\n",
    "#     # hits = row['corpus-id']\n",
    "\n",
    "#     # cross_inp = [[query, corpus_df.loc[hit].text] for hit in hits]\n",
    "#     # cross_scores = cross_encoder.predict(cross_inp)\n",
    "#     # # make all the scores positive\n",
    "#     # cross_scores = [math.exp(score) for score in cross_scores]\n",
    "\n",
    "#     # task2_results.append(cross_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94ca6ec6ba84eae82ccf5552c230d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "# iterate row by row\n",
    "task2_results = []\n",
    "for index, row in tqdm(test_data2.iterrows(), total=len(test_data2)):\n",
    "    query = queries_df.loc[row['query-id']]['text']\n",
    "\n",
    "\n",
    "    hits = row['corpus-id']\n",
    "\n",
    "    cross_inp = [[query, corpus_df.loc[hit].text] for hit in hits]\n",
    "    cross_scores = cross_encoder.predict(cross_inp)\n",
    "    # cross_scores is currently of shape len(hits)x4\n",
    "    # we need to get the label with the highest score\n",
    "    # cross_scores = np.argmax(cross_scores, axis=1)\n",
    "    # make all the scores positive\n",
    "    # cross_scores = [math.exp(score) for score in cross_scores]\n",
    "\n",
    "    task2_results.append(cross_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save task2 results to a pickle file\n",
    "import pickle\n",
    "with open(f'{DATA_DIR}/task2_results_custom.pkl', 'wb') as f:\n",
    "    pickle.dump(task2_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a csv file for submission\n",
    "# HEADER: id,corpus-id,score\n",
    "# task1 results will be: query-id,[corpus-id1, corpus-id2, ...] (top 10 corpus-ids), -1\n",
    "# task2 results will be query-id, -1, [score1, score2...] \n",
    "# create the file\n",
    "\n",
    "with open(f'{DATA_DIR}/sentence-transformers_submission7.csv', 'w') as f:\n",
    "    id = 0\n",
    "    f.writelines('id,corpus-id,score\\n')\n",
    "    for i, row in enumerate(task1_results_final):\n",
    "        to_write = \"\\\"[\"\n",
    "        for j, corpus_id in enumerate(row):\n",
    "            if j != len(row)-1:\n",
    "                to_write += str(corpus_id) + \", \"\n",
    "            else:\n",
    "                to_write += str(corpus_id)\n",
    "        to_write += \"]\\\"\"\n",
    "        f.write(str(id) + \",\" + to_write + \",-1\\n\")\n",
    "        id += 1\n",
    "\n",
    "    for i,row in enumerate(task2_results):\n",
    "        query_id_to_write = test_data2.iloc[i]['query-id']\n",
    "        to_write = \"\\\"[\"\n",
    "        for j, score in enumerate(row):\n",
    "            if j != len(row)-1:\n",
    "                to_write += str(score) + \", \"\n",
    "            else:\n",
    "                to_write += str(score) \n",
    "        to_write += \"]\\\"\"\n",
    "        f.write(str(id) + \",-1,\" + to_write + \"\\n\")\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
